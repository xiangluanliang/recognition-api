# scripts/generate_daily_report.py

import os
import django
from datetime import datetime, timedelta
from django.db.models import Count
from django.utils import timezone

import sys
# print(sys.path)

# è®¾ç½® Django ç¯å¢ƒ
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings.test')
django.setup()

from api.models import EventLog, Camera, DailyReport, AlarmLog

from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# æ›¿æ¢æ¨¡å‹åŠ è½½éƒ¨åˆ†ï¼š
model_name = "Qwen/Qwen1.5-0.5B-Chat"

tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True).eval()

model = model.eval()


def collect_data():
    today = timezone.localdate()
    start = timezone.make_aware(datetime.combine(today, datetime.min.time()))
    end = timezone.make_aware(datetime.combine(today, datetime.max.time()))

    alarms = AlarmLog.objects.filter(time__range=(start, end))

    summary = {}

    # æ—¥æœŸä¿¡æ¯
    summary['æ—¥æœŸ'] = str(today)

    # æ€»ä½“å‘Šè­¦æƒ…å†µ
    summary['æ€»äº‹ä»¶æ•°'] = alarms.count()
    summary['æœªå¤„ç†äº‹ä»¶æ•°'] = alarms.filter(status=0).count()
    summary['å¤„ç†ä¸­äº‹ä»¶æ•°'] = alarms.filter(status=1).count()
    summary['å·²å¤„ç†äº‹ä»¶æ•°'] = alarms.filter(status=2).count()

    # å‘Šè­¦ç±»å‹ç»Ÿè®¡ï¼ˆç”¨ä¸­æ–‡ï¼‰
    EVENT_TYPE_MAP = dict(EventLog.EVENT_TYPE_CHOICES)
    type_counts = alarms.values('event__event_type').annotate(count=Count('id'))
    type_summary = {}
    for item in type_counts:
        etype = item['event__event_type']
        cname = EVENT_TYPE_MAP.get(etype, etype)
        type_summary[cname] = item['count']
    summary['äº‹ä»¶ç±»å‹ç»Ÿè®¡'] = type_summary

    # æ‘„åƒå¤´æƒ…å†µ
    total_cameras = Camera.objects.count()
    active_cameras = Camera.objects.filter(is_active=True).count()
    summary['æ‘„åƒå¤´æ€»æ•°'] = total_cameras
    summary['åœ¨çº¿æ‘„åƒå¤´'] = active_cameras
    summary['ç¦»çº¿æ‘„åƒå¤´'] = total_cameras - active_cameras

    return summary

    # summary = {
    #     'æ—¥æœŸ': '2025-07-13',
    #     'æ€»äº‹ä»¶æ•°': 14,
    #     'æœªå¤„ç†äº‹ä»¶æ•°': 3,
    #     'å¤„ç†ä¸­äº‹ä»¶æ•°': 4,
    #     'å·²å¤„ç†äº‹ä»¶æ•°': 7,
    #     'ç±»å‹:face_match': 5,
    #     'ç±»å‹:fire': 2,
    #     'ç±»å‹:intrusion': 6,
    #     'ç±»å‹:conflict': 1,
    #     'æ‘„åƒå¤´æ€»æ•°': 20,
    #     'åœ¨çº¿æ‘„åƒå¤´': 18,
    # }


def build_prompt(summary):
    prompt = (
        "ä½ æ˜¯ä¸€ä¸ªå®‰é˜²ç›‘æ§ç³»ç»Ÿçš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ä»¥ä¸‹ç›‘æ§ç»Ÿè®¡æ•°æ®ï¼Œæ’°å†™ä¸€ä»½çº¦ 300 å­—çš„ä¸­æ–‡å®‰é˜²ç›‘æ§æ—¥æŠ¥ã€‚"
        "å†…å®¹åº”åŒ…æ‹¬ä»¥ä¸‹å››éƒ¨åˆ†ï¼ˆä½¿ç”¨å°æ ‡é¢˜åˆ†æ®µï¼‰ï¼šâ‘ äº‹ä»¶æ€»ä½“æƒ…å†µï¼Œâ‘¡äº‹ä»¶ç±»å‹åˆ†å¸ƒï¼Œâ‘¢æ‘„åƒå¤´çŠ¶æ€ï¼Œâ‘£é£é™©æç¤ºå»ºè®®ã€‚\n"
        "æ³¨æ„ï¼šä¸è¦ç¼–é€ æˆ‘æœªæä¾›çš„ä¿¡æ¯ï¼Œä¸è¦åšè¿‡å¤šä¸»è§‚çŒœæµ‹ã€‚\n"
        "ç‰¹åˆ«è¯´æ˜ï¼š'åŒºåŸŸå…¥ä¾µ' æ˜¯æŒ‡æ£€æµ‹åˆ°äººå‘˜è¿›å…¥äº†ä¸å…è®¸è¿›å…¥çš„å®‰å…¨åŒºåŸŸã€‚\n\n"
    )

    prompt += f"ğŸ“… æ—¥æœŸï¼š{summary['æ—¥æœŸ']}\n"
    prompt += f"ğŸ“Š æ€»æŠ¥è­¦äº‹ä»¶æ•°ï¼š{summary['æ€»äº‹ä»¶æ•°']}\n"
    prompt += f"ğŸ”´ æœªå¤„ç†ï¼š{summary['æœªå¤„ç†äº‹ä»¶æ•°']}ï¼ŒğŸŸ  å¤„ç†ä¸­ï¼š{summary['å¤„ç†ä¸­äº‹ä»¶æ•°']}ï¼ŒğŸŸ¢ å·²å¤„ç†ï¼š{summary['å·²å¤„ç†äº‹ä»¶æ•°']}\n\n"

    prompt += "ğŸ“Œ äº‹ä»¶ç±»å‹ç»Ÿè®¡ï¼š\n"
    for k, v in summary['äº‹ä»¶ç±»å‹ç»Ÿè®¡'].items():
        prompt += f"- {k}ï¼š{v} èµ·\n"

    prompt += "\nğŸ¥ æ‘„åƒå¤´çŠ¶æ€ï¼š\n"
    prompt += f"- æ€»æ•°ï¼š{summary['æ‘„åƒå¤´æ€»æ•°']}ï¼Œåœ¨çº¿ï¼š{summary['åœ¨çº¿æ‘„åƒå¤´']}ï¼Œç¦»çº¿ï¼š{summary['ç¦»çº¿æ‘„åƒå¤´']}\n"

    prompt += (
        "\nğŸ›¡ï¸ è¯·ä½¿ç”¨æ¸…æ™°çš„å°æ ‡é¢˜ï¼Œè¾“å‡ºä¸€æ®µ 300 å­—çš„è‡ªç„¶è¯­è¨€ä¸­æ–‡æŠ¥å‘Šï¼Œæ€»ç»“ä¸Šè¿°ç›‘æ§æƒ…å†µã€‚\n"
        "ä¸è¦æåŠæç¤ºè¯ã€æˆ‘æä¾›çš„æ•°æ®ä¹‹å¤–çš„å†…å®¹ï¼Œä¹Ÿä¸è¦ä½¿ç”¨å‡è®¾æˆ–è‡†æµ‹è¯­æ°”ã€‚"
    )

    return prompt.strip()


#     prompt = """
# ä½ æ˜¯ä¸€ä¸ªå®‰é˜²ç›‘æ§ç³»ç»Ÿçš„æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ä»¥ä¸‹æ•°æ®ç”Ÿæˆä¸€ä»½ç®€æ˜çš„ä¸­æ–‡ç›‘æ§æ—¥æŠ¥ã€‚
# åŒ…æ‹¬ï¼šæ€»ä½“äº‹ä»¶æ¦‚å†µã€å„ç±»å‹äº‹ä»¶æƒ…å†µã€æ‘„åƒå¤´åœ¨çº¿çŠ¶æ€ï¼Œä»¥åŠå¿…è¦æ—¶çš„é£é™©æç¤ºã€‚
#
# ä¸‹é¢æ˜¯å½“å¤©çš„ç›‘æ§æ•°æ®æ‘˜è¦ï¼š
# """
#     for k, v in summary.items():
#         prompt += f"- {k}: {v}\n"
#     prompt += """
#
# è¯·è¾“å‡ºä¸€æ®µè‡ªç„¶è¯­è¨€æè¿°ï¼Œæ€»ç»“å½“å¤©ç›‘æ§æƒ…å†µã€‚
# """
#     return prompt.strip()


def generate_text_report():
    summary = collect_data()
    prompt = build_prompt(summary)

    print("\n=== ğŸ“¥ Prompt è¾“å…¥ ===\n")
    print(prompt)

    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå®‰é˜²ç›‘æ§ç³»ç»Ÿçš„æ™ºèƒ½åŠ©æ‰‹"},
        {"role": "user", "content": prompt}
    ]

    input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)

    inputs = tokenizer(input_text, return_tensors="pt").to(model.device)

    # æ¨¡å‹æ¨ç†
    outputs = model.generate(**inputs, max_new_tokens=512)

    # è§£ç æ¨¡å‹è¾“å‡ºéƒ¨åˆ†ï¼ˆå»æ‰è¾“å…¥å†…å®¹ï¼‰
    response = tokenizer.decode(outputs[0][inputs.input_ids.shape[-1]:], skip_special_tokens=True)

    print("\n=== ğŸ“¤ æ¨¡å‹è¾“å‡ºï¼ˆç”Ÿæˆçš„æ—¥æŠ¥ï¼‰ ===\n")
    print(response)
    # å†™å…¥æ•°æ®åº“
    # DailyReport.objects.update_or_create(date=timezone.localdate(), defaults={'content': content})
    # print("âœ… æ—¥æŠ¥å·²ç”Ÿæˆå¹¶å†™å…¥æ•°æ®åº“ï¼š\n", content)


if __name__ == '__main__':
    print("\n=== ğŸ§ª collect_data() è¿”å›ç»“æœ ===\n")
    from pprint import pprint
    pprint(collect_data())

    generate_text_report()
